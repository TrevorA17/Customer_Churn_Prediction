---
title: "Customer Churn Prediction"
author: "134780 Trevor Okinda"
date: "April 2024"
output:
  github_document: 
    toc: yes
    toc_depth: 4
    fig_width: 6
    fig_height: 4
    df_print: default
editor_options:
  chunk_output_type: console
---

# Student Details

|                                              |     |
|----------------------------------------------|-----|
| **Student ID Number**                        | 134780 |
| **Student Name**                             | Trevor Okinda |
| **BBIT 4.2 Group**                           | C |
| **Project Name**                             | Customer Churn Prediction Model |

# Setup Chunk

**Note:** the following KnitR options have been set as the global defaults: <BR> `knitr::opts_chunk$set(echo = TRUE, warning = FALSE, eval = TRUE, collapse = FALSE, tidy = TRUE)`.

More KnitR options are documented here <https://bookdown.org/yihui/rmarkdown-cookbook/chunk-options.html> and here <https://yihui.org/knitr/options/>.

```{r setup, include=FALSE}
library(formatR)
knitr::opts_chunk$set(
  warning = FALSE,
  collapse = FALSE
)
```

```{r Load Dataset}
# Load dataset
churn_data <- read.csv("Telco_customer_churn.csv", colClasses = c(
  CustomerID = "character",
  Count = "factor",
  Country = "factor",
  State = "factor",
  City = "factor",
  Zip_Code = "factor",
  Lat_Long = "character",
  Latitude = "numeric",
  Longitude = "numeric",
  Gender = "factor",
  Senior_Citizen = "factor",
  Partner = "factor",
  Dependents = "factor",
  Tenure_Months = "numeric",
  Phone_Service = "factor",
  Multiple_Lines = "factor",
  Internet_Service = "factor",
  Online_Security = "factor",
  Online_Backup = "factor",
  Device_Protection = "factor",
  Tech_Support = "factor",
  Streaming_TV = "factor",
  Streaming_Movies = "factor",
  Contract = "factor",
  Paperless_Billing = "factor",
  Payment_Method = "factor",
  Monthly_Charges = "numeric",
  Total_Charges = "numeric",
  Churn_Label = "factor",
  Churn_Value = "numeric",
  Churn_Score = "numeric",
  CLTV = "numeric",
  Churn_Reason = "factor"
))

# Display the structure of the dataset
str(churn_data)

# View the first few rows of the dataset
head(churn_data)

View(churn_data)
```

```{r Measures of Frequency}
#Measures of Frequency
# Load dataset (assuming it's already loaded as churn_data)

# Define categorical variables
categorical_vars <- c("Count", "Country", "State", "City", "Zip_Code", 
                      "Gender", "Senior_Citizen", "Partner", "Dependents",
                      "Phone_Service", "Multiple_Lines", "Internet_Service",
                      "Online_Security", "Online_Backup", "Device_Protection",
                      "Tech_Support", "Streaming_TV", "Streaming_Movies",
                      "Contract", "Paperless_Billing", "Payment_Method",
                      "Churn_Label", "Churn_Reason")

# Generate measures of frequency for each categorical variable
for (var in categorical_vars) {
  cat(paste("Frequency table for variable:", var, "\n"))
  print(table(churn_data[[var]]))
  cat("\n")
}
```

```{r Measures of Central Tendency}
# Measures of central tendency
# Define numerical variables
numerical_vars <- c("Tenure_Months", "Monthly_Charges", "Total_Charges", 
                    "Churn_Value", "Churn_Score", "CLTV")

# Generate measures of central tendency for each numerical variable
for (var in numerical_vars) {
  cat(paste("Measures of central tendency for variable:", var, "\n"))
  print(summary(churn_data[[var]]))
  cat("\n")
}
```

```{r Measures of Distribution}
#Measures of Distribution

# Load required package
library(e1071)

# Define numerical variables
numerical_vars <- c("Tenure_Months", "Monthly_Charges", "Total_Charges", 
                    "Churn_Value", "Churn_Score", "CLTV")

# Generate measures of distribution for each numerical variable
for (var in numerical_vars) {
  cat(paste("Measures of distribution for variable:", var, "\n"))
  cat("Skewness:", skewness(churn_data[[var]]), "\n")
  cat("Kurtosis:", kurtosis(churn_data[[var]]), "\n")
  cat("\n")
}
```

```{r Measures of Relationship}
# Measures of Relationship

# Load required package
library(MASS)  # For the chi-square test

# Define variables
numerical_vars <- c("Tenure_Months", "Monthly_Charges", "Total_Charges", 
                    "Churn_Value", "Churn_Score", "CLTV")

categorical_vars <- c("Count", "Country", "State", "City", "Zip_Code", 
                      "Gender", "Senior_Citizen", "Partner", "Dependents",
                      "Phone_Service", "Multiple_Lines", "Internet_Service",
                      "Online_Security", "Online_Backup", "Device_Protection",
                      "Tech_Support", "Streaming_TV", "Streaming_Movies",
                      "Contract", "Paperless_Billing", "Payment_Method",
                      "Churn_Label", "Churn_Reason")

# Compute measures of relationship for numerical variables (correlation)
cat("Correlation coefficients for numerical variables:\n")
correlation_matrix <- cor(churn_data[, numerical_vars])
print(correlation_matrix)

# Compute measures of relationship for categorical variables (chi-square test)
for (var in categorical_vars) {
  cat(paste("Chi-square test for variable:", var, "\n"))
  cross_tab <- table(churn_data[[var]], churn_data$Churn_Label)
  chi_square_test <- chisq.test(cross_tab)
  print(chi_square_test)
  cat("\n")
}
```

```{r ANOVA}
# ANOVA
# Define the categorical variable (factor)
categorical_var <- "Contract"  

# Define the numerical variable (response)
numerical_var <- "Monthly_Charges"  

# Perform ANOVA
anova_result <- aov(churn_data[[numerical_var]] ~ churn_data[[categorical_var]])

# Summarize ANOVA results
summary(anova_result)

```

```{r Missingness}
# Missing Values

# Check for missing values in the dataset
missing_values <- colSums(is.na(churn_data))

# Display columns with missing values
cols_with_missing <- names(missing_values[missing_values > 0])
print(cols_with_missing)

# Summarize the count of missing values for each column
print(missing_values)
```

```{r Imputation}
# Perform mean imputation for each column with missing values
for (col in cols_with_missing) {
  mean_value <- mean(churn_data[[col]], na.rm = TRUE)  # Compute mean of the column
  churn_data[[col]][is.na(churn_data[[col]])] <- mean_value  # Replace missing values with mean
}

# Verify that missing values have been imputed
missing_values_after_imputation <- colSums(is.na(churn_data))
print(missing_values_after_imputation)
```

```{r Transformation}
# Data Transformation
# Identify factor variables with only one level
factor_vars <- sapply(churn_data, is.factor)
single_level_vars <- names(churn_data)[sapply(churn_data[factor_vars], function(x) length(unique(x)) == 1)]

# Print variables with only one level
print(single_level_vars)

# Transform factor variables with only one level to numeric
for (var in single_level_vars) {
  churn_data[[var]] <- as.numeric(churn_data[[var]])
}
```

```{r Data Splitting}
# Load required package
library(caret)  # For data splitting

# Set seed for reproducibility
set.seed(123)

# Specify the proportion of data for training (e.g., 80%)
train_proportion <- 0.8

# Split the dataset into training and testing sets
train_indices <- createDataPartition(churn_data$Churn_Label, p = train_proportion, list = FALSE)
train_data <- churn_data[train_indices, ]
test_data <- churn_data[-train_indices, ]

# Display the dimensions of the training and testing sets
cat("Training set size:", nrow(train_data), "\n")
cat("Testing set size:", nrow(test_data), "\n")
```

```{r Boostrapping}
# Load required package
library(boot)  # For bootstrapping

# Define your statistic of interest (mean)
mean_function <- function(data, indices) {
  sample <- data[indices, "Tenure_Months"]
  return(mean(sample))
}

# Set the number of bootstrap iterations
num_iterations <- 1000

# Perform bootstrapping
bootstrap_results <- boot(data = churn_data, statistic = mean_function, R = num_iterations)

# Summarize bootstrap results
print(bootstrap_results)
```

```{r Cross-Validation}
#Cross- Validation

# Select subset of columns (adjust as needed)
selected_columns <- c("Tenure_Months", "Monthly_Charges", "Total_Charges", "Gender", "Senior_Citizen", "Churn_Label")

# Subset the dataset based on selected columns
churn_data_subset <- churn_data[, selected_columns]

#Basic Cross-Validation
# Load required package
library(caret)

# Define control parameters for cross-validation
ctrl <- trainControl(method = "cv", number = 5)

# Specify the method as "svmRadial" for SVM
model <- train(Churn_Label ~ ., data = churn_data_subset, method = "svmRadial", trControl = ctrl)

# Print the model results
print(model)


#Repeated Cross-Validation
# Set the number of folds and repetitions
num_folds <- 5  
num_repeats <- 3  

# Define the control parameters for repeated cross-validation
ctrl_repeated <- trainControl(method = "repeatedcv", number = num_folds, repeats = num_repeats)

# Train the model using repeated k-fold cross-validation
model_repeated <- train(Churn_Label ~ ., data = churn_data_subset, method = "svmRadial", trControl = ctrl_repeated)

# Print the model results
print(model_repeated)
```

```{r Model Training}
# Define control parameters for cross-validation
ctrl <- trainControl(method = "cv", number = 5)

# Train the logistic regression model
model_logistic <- train(Churn_Label ~ ., data = churn_data_subset, method = "glm", trControl = ctrl, family = "binomial")

# Print the model results
print(model_logistic)

# Train the decision tree model
model_tree <- train(Churn_Label ~ ., data = churn_data_subset, method = "rpart", trControl = ctrl)

# Print the model results
print(model_tree)

# Train the neural network model for classification
model_neural <- train(Churn_Label ~ ., data = churn_data_subset, method = "nnet", trControl = ctrl)

# Print the model results
print(model_neural)
```

```{r Performance Comparison Using resamples}
#Perfomance Comparison Using Resamples
# Load required package
library(caret)

# Define control parameters for cross-validation
ctrl <- trainControl(method = "cv", number = 5)

# Train the logistic regression model
model_logistic <- train(Churn_Label ~ ., data = churn_data_subset, method = "glm", trControl = ctrl, family = "binomial")

# Train the decision tree model
model_tree <- train(Churn_Label ~ ., data = churn_data_subset, method = "rpart", trControl = ctrl)

# Train the neural network model
model_neural <- train(Churn_Label ~ ., data = churn_data_subset, method = "nnet", trControl = ctrl)

# Create a list of models
models <- list(logistic = model_logistic, tree = model_tree, neural = model_neural)

# Compare model performance using resamples
resamples <- resamples(models)

# Summarize model performance
summary(resamples)
```

```{r Saving Model}
# Saving the neural network model
saveRDS(model_neural, "./models/saved_neural_model.rds")

# Load the saved model
loaded_neural_model <- readRDS("./models/saved_neural_model.rds")

# Prepare new data for prediction (using churn dataset variables)
new_data <- data.frame(
  Tenure_Months = 10,
  Monthly_Charges = 50,
  Total_Charges = 500,
  Contract = "Month-to-month",
  Paperless_Billing = "Yes",
  Payment_Method = "Electronic check",
  Senior_Citizen = "No",
  Dependents = "Yes",
  Partner = "Yes",
  Gender = "Female",
  Internet_Service = "Fiber optic",
  Online_Security = "Yes",
  Tech_Support = "Yes"
)

# Use the loaded model to make predictions
predictions_loaded_model <- predict(loaded_neural_model, newdata = new_data)

# Print predictions
print(predictions_loaded_model)

```

